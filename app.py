# app.py

import streamlit as st
import pandas as pd
import numpy as np
import os
import io
from docx import Document
import time
from data_processor import load_fixed_data, analyze_merchant, FIXED_DATA_PATH
from gemini_api import generate_marketing_text_with_gemini, generate_chat_response_with_gemini
from visualize import load_data
from visualize import kpi_board, gender_age_pie, customer_type_pie_revisit_new, customer_type_pie_origin
from mbti_classifier import classify_merchant_mbti
from visualization_area import render_area_dashboard
from clustering import get_dtw_cluster, build_dtw_report

def load_area_cluster_data():
    """area_cluster.csv íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ìºì‹œ í•¨ìˆ˜"""
    # data_dong.csvê°€ ìˆëŠ” í´ë”(FIXED_DATA_PATH) ê¸°ì¤€ìœ¼ë¡œ area_cluster.csv ê²½ë¡œ ì„¤ì •
    cluster_file_path = os.path.join(os.path.dirname(FIXED_DATA_PATH), "area_clustering.csv")
    
    if not os.path.exists(cluster_file_path):
        st.error(f"âŒ 'area_cluster.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {cluster_file_path}")
        return None
    try:
        # area_cluster.csv íŒŒì¼ ì¸ì½”ë”©ì— ë§ê²Œ 'utf-8' ë˜ëŠ” 'cp949' ì‹œë„
        df = pd.read_csv(cluster_file_path, encoding='utf-8')
    except UnicodeDecodeError:
        df = pd.read_csv(cluster_file_path, encoding='cp949')
    except Exception as e:
        st.error(f"âŒ 'area_cluster.csv' ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    return df

@st.cache_resource(ttl=3600)
def cached_load_data(path):
    """Streamlit ìºì‹±ì„ ì ìš©í•œ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜"""
    try:
        return load_fixed_data(path)
    except (FileNotFoundError, UnicodeDecodeError, ValueError, Exception) as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.info("FIXED_DATA_PATH ë³€ìˆ˜ê°€ ì •í™•í•œì§€, íŒŒì¼ì´ í•´ë‹¹ ê²½ë¡œì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
        return None
    
def create_docx_report(mct_id, proposal, chat_history):
    """ë§ˆì¼€íŒ… ì „ëµê³¼ ì±—ë´‡ ëŒ€í™” ë‚´ìš©ìœ¼ë¡œ Word ë¬¸ì„œë¥¼ ìƒì„±í•˜ì—¬ ë°”ì´íŠ¸ ê°ì²´ë¡œ ë°˜í™˜"""
    doc = Document()
    doc.add_heading(f"'{mct_id}' ê°€ë§¹ì  AI ë§ˆì¼€íŒ… ë¶„ì„ ë¦¬í¬íŠ¸", level=1)
    doc.add_paragraph()

    doc.add_heading("ğŸš€ AI ë¹„ë°€ìƒë‹´ì‚¬ì˜ ë§ì¶¤í˜• ë§ˆì¼€íŒ… í”Œëœ", level=2)
    for line in proposal.split('\n'):
        doc.add_paragraph(line)
    
    if len(chat_history) > 1:
        doc.add_paragraph()
        doc.add_heading("ğŸ¤– ì¶”ê°€ ìƒë‹´ ë‚´ìš© (Q&A)", level=2)
        for message in chat_history[1:]:
            role = "Q (ì‚¬ìš©ì)" if message["role"] == "user" else "A (AI ìƒë‹´ì‚¬)"
            p = doc.add_paragraph()
            p.add_run(f"{role}: ").bold = True
            p.add_run(message['content'])
            doc.add_paragraph()
            
    buffer = io.BytesIO()
    doc.save(buffer)
    return buffer.getvalue()

def create_cluster_report_docx(
    mct_id: str,
    h_dong: str,
    industry_name: str,
    selected_industry_mapped: str,
    cluster_text: str,
    similar_dong_sentence: str,
    cluster_description: str,
    all_desc: str
) -> bytes:
    """ì—…ì¥ ë³´ê³ ì„œ(ìƒê¶Œ í´ëŸ¬ìŠ¤í„°) íƒ­ì˜ ë‚´ìš©ì„ Word ë¬¸ì„œë¡œ ìƒì„±í•˜ì—¬ ë°”ì´íŠ¸ ê°ì²´ë¡œ ë°˜í™˜"""
    doc = Document()
    doc.add_heading(f"'{mct_id}' ê°€ë§¹ì  ìƒê¶Œ(ì—…ì¥) ë¶„ì„ ë¦¬í¬íŠ¸", level=1)
    doc.add_paragraph()

    # 1. í•µì‹¬ ë¶„ì„ ê²°ê³¼
    doc.add_heading("ğŸ“Œ í•µì‹¬ ë¶„ì„ ê²°ê³¼", level=2)
    
    # h_dong, industry_name ë“± ì£¼ìš” ì •ë³´ë¥¼ êµµê²Œ ì²˜ë¦¬
    p1 = doc.add_paragraph()
    p1.add_run(f"ì ì£¼ë‹˜ì˜ ì—…ì¥ (").bold = False
    p1.add_run(f"{h_dong}, {industry_name}").bold = True
    p1.add_run(f")ì€(ëŠ”) ").bold = False
    p1.add_run(f"[{selected_industry_mapped}-{cluster_text}]").bold = True
    p1.add_run("ì— í•´ë‹¹í•©ë‹ˆë‹¤.").bold = False
    
    # ìœ ì‚¬ í–‰ì •ë™ ë¬¸ì¥ (êµµê²Œ ì²˜ë¦¬ëœ ë§ˆí¬ë‹¤ìš´ ì œê±°)
    if similar_dong_sentence:
        clean_sentence = similar_dong_sentence.replace("**", "") # ë§ˆí¬ë‹¤ìš´ ** ì œê±°
        clean_sentence = clean_sentence.replace("[", "").replace("]", "") # [ ] ì œê±°
        doc.add_paragraph(clean_sentence)
        
    doc.add_paragraph() # ì—¬ë°±

    # 2. ìƒì„¸ ë¶„ì„ (í•´ë‹¹ í´ëŸ¬ìŠ¤í„°)
    if cluster_description:
        doc.add_heading(f"â¡ï¸ {cluster_text} ìƒì„¸ ë¶„ì„", level=2)
        # í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì¤„ë°”ê¿ˆ(ê°œí–‰)ì„ docxì— ë°˜ì˜
        for line in cluster_description.split('\n'):
            doc.add_paragraph(line)
        doc.add_paragraph() # ì—¬ë°±

    # 3. ì—…ì¢… ì „ì²´ ìš”ì•½
    if all_desc:
        doc.add_heading(f"'{selected_industry_mapped}' ì—…ì¢… ì „ì²´ ìš”ì•½", level=2)
        for line in all_desc.split('\n'):
            doc.add_paragraph(line)
            
    # ë²„í¼ì— ì €ì¥í•˜ì—¬ ë°˜í™˜
    buffer = io.BytesIO()
    doc.save(buffer)
    return buffer.getvalue()

# -------------------- ë©”ì¸ ì‹œì‘ -------------------- #
def main():
    st.set_page_config(layout="wide", page_title="ğŸ’¡ ë‚´ ê°€ê²Œë¥¼ ì‚´ë¦¬ëŠ” AI ë¹„ë°€ìƒë‹´ì‚¬")
    st.markdown("""
    <div style="background-color:#f0f2f6; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
    <h1 style="text-align: center; color: black; margin: 0; font-size: 2.5rem;">ğŸ’¡ ë‚´ ê°€ê²Œë¥¼ ì‚´ë¦¬ëŠ” AI ë¹„ë°€ìƒë‹´ì‚¬</h1>
    </div>
    """, unsafe_allow_html=True)
    #st.markdown("ë°ì´í„°ì™€ AIë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš°ë¦¬ ê°€ê²Œì˜ ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ê³ , í•µì‹¬ ê³ ê°ì„ ìœ„í•œ ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµì„ ì°¾ì•„ë³´ì„¸ìš”.")

# --- Session State ì´ˆê¸°í™” --- #
    if 'generating' not in st.session_state:
        st.session_state['generating'] = False
    if 'chat_messages' not in st.session_state:
        st.session_state['chat_messages'] = []
    
# --- ë°ì´í„° ë¡œë“œ & ìºì‹œ --- #
    if 'df_profile' not in st.session_state:
        with st.spinner('ì´ˆê¸° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            df_profile = cached_load_data(FIXED_DATA_PATH)
            if df_profile is None:
                st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            st.session_state['df_profile'] = df_profile

    df_profile = st.session_state['df_profile']

    # --- ê°€ë§¹ì  ID ìºì‹œ --- #
    if 'merchant_ids' not in st.session_state:
        merchant_ids = (
            df_profile['ENCODED_MCT']
            .dropna()
            .astype(str)
            .unique()
            .tolist()
        )
        merchant_ids.sort()
        st.session_state['merchant_ids'] = merchant_ids

    all_merchant_ids = st.session_state['merchant_ids']

    st.sidebar.header("ì‹œì‘í•˜ê¸°")

    # -------------------- ì‚¬ì´ë“œë°” -------------------- #
    # 1. ê°€ë§¹ì  ì„ íƒ
    merchant_ids = df_profile["ENCODED_MCT"].unique().tolist()

    with st.sidebar:
        search_term = st.text_input(
            "ê°€ë§¹ì  ì„ íƒí•˜ê¸°",
            placeholder="ì—¬ê¸°ì— ê°€ë§¹ì  ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        ).strip()

        if search_term:
            filtered_merchants = [m for m in merchant_ids if search_term in m]
        else:
            filtered_merchants = merchant_ids

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ selectbox í‘œì‹œ, ì—†ìœ¼ë©´ ì•ˆë‚´
        if filtered_merchants:
            selected_mct = st.selectbox(
                "ë¶„ì„í•  ê°€ë§¹ì ì„ ì„ íƒí•˜ì„¸ìš”:",
                filtered_merchants,
                key="merchant_selector",
                label_visibility="collapsed"
            )
        else:
            st.info("ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            selected_mct = None

    if not selected_mct:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ê°€ë§¹ì ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()


    # -------------------- ê°€ë§¹ì  ê¸°ë³¸ ì •ë³´ ë¸”ë¡ -------------------- #
    if selected_mct:
        try:
            row = df_profile.loc[df_profile["ENCODED_MCT"].astype(str) == str(selected_mct)].iloc[0]
        except IndexError:
            st.sidebar.info("ì„ íƒí•œ ê°€ë§¹ì ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            with st.sidebar.expander("ğŸ“‚ ê°€ê²Œ ì •ë³´", expanded=True):
                status = "ìš´ì˜ ì¤‘" if pd.isna(row.get("MCT_ME_D")) else f"íì—… ({row.get('MCT_ME_D')})"
                st.markdown(f"**ì—…ì¢…:** {row.get('HPSN_MCT_ZCD_NM')}")
                st.markdown(f"**ì£¼ì†Œ:** {row.get('MCT_BSE_AR')}")
                st.markdown(f"**ìƒê¶Œ:** {row.get('h_name', row.get('HPSN_MCT_BZN_CD_NM'))}")
                st.markdown(f"**ìƒíƒœ:** {status}")

            # MBTI(ê°€ê²Œ ìœ í˜•) ë¶„ë¥˜ â€” ê¸°ì¡´ UI ìœ ì§€
            store_type = classify_merchant_mbti(row)
            with st.sidebar.expander("ğŸª ê°€ê²Œ ìœ í˜• (MBTI)", expanded=True):
                st.markdown(f"**{store_type['name']}**")
                st.caption(store_type['description'])
    else:
        st.sidebar.info("ê°€ë§¹ì ì„ ì„ íƒí•˜ë©´ ê¸°ë³¸ ì •ë³´ì™€ ê°€ê²Œ ìœ í˜•ì´ í‘œì‹œë©ë‹ˆë‹¤.")

    # -------------------- ê¸°ì¤€ì›” ì„ íƒ -------------------- #
    st.session_state["selected_mct"] = selected_mct
    @st.cache_data(ttl=3600)
    def _load_viz_df():
        return load_data()

    if "viz_df" not in st.session_state:
        st.session_state["viz_df"] = _load_viz_df()
    viz_df = st.session_state["viz_df"]

    col_title, col_month = st.columns([3, 1], gap="large")
    with col_title:
        pass  # ì´ë¯¸ ìœ„ì—ì„œ íƒ€ì´í‹€/ì„¤ëª… ë Œë”ë§

    with col_month:
        mct_for_month = st.session_state.get("selected_mct")  # â† ì§€ì—­ë³€ìˆ˜ ëŒ€ì‹  ì„¸ì…˜ê°’ ì‚¬ìš©
        if mct_for_month:
            mct_dates = (
                viz_df.loc[viz_df["ENCODED_MCT"] == mct_for_month, "TA_YM_DT"]
                .dropna().sort_values(ascending=False)
                .dt.to_period("M").drop_duplicates().tolist()
            )
            month_options = ["-- ê¸°ì¤€ì›”ì„ ì„ íƒí•˜ì„¸ìš” --"] + [p.to_timestamp() for p in mct_dates]
        else:
            month_options = ["-- ê¸°ì¤€ì›”ì„ ì„ íƒí•˜ì„¸ìš” --"]

        selected_ref = st.selectbox(
            "ğŸ“… ë‚ ì§œ",
            month_options, index=0,
            format_func=lambda d: d if isinstance(d, str) else d.strftime("%Y-%m"),
            key="ref_month_selector",
        )
        if selected_ref == "-- ê¸°ì¤€ì›”ì„ ì„ íƒí•˜ì„¸ìš” --":
            selected_ref = None


    # -------------------- ë©”ì¸ í™”ë©´ -------------------- #
    # 1ï¸âƒ£ ê°€ë§¹ì  ì„ íƒ í›„ ë¶„ì„ ì‹¤í–‰
    if selected_mct is None:
        st.session_state["analysis_result"] = None
    else:
        df_mct = df_profile[df_profile["ENCODED_MCT"] == selected_mct]
        if df_mct.empty:
            st.warning("ì„ íƒí•œ ê°€ë§¹ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.session_state["analysis_result"] = None
        else:
            if (
                "last_mct" not in st.session_state
                or "last_ref" not in st.session_state
                or st.session_state["last_mct"] != selected_mct
                or st.session_state["last_ref"] != selected_ref
            ):
                with st.spinner("ê°€ë§¹ì  ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    st.session_state["analysis_result"] = analyze_merchant(df_mct.iloc[0])

                st.session_state["last_mct"] = selected_mct
                st.session_state["last_ref"] = selected_ref
                st.session_state["marketing_proposal"] = ""
                st.session_state["show_mbti_description"] = False
    # 2ï¸âƒ£ íƒ­ ì„ ì–¸
    tab_llm, tab_viz, tab_area, tab_clu = st.tabs(["ğŸ¤– AI ë§ˆì¼€íŒ…", "ğŸ“Š ì›”ë³„ ë³´ê³ ì„œ", "ğŸ“ ìƒê¶Œ ë³´ê³ ì„œ", "â¤ï¸ ì—…ì¥ ë³´ê³ ì„œ"])

    # 3ï¸âƒ£ ì•ˆì „ ê°€ë“œ
    if (
        "analysis_result" not in st.session_state
        or st.session_state["analysis_result"] is None
    ):
        st.warning("ì•„ì§ ê°€ë§¹ì ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    # 4ï¸âƒ£ ì„¸ì…˜ì—ì„œ ê²°ê³¼ êº¼ë‚´ì˜¤ê¸°
    analysis_result = st.session_state["analysis_result"]
    summary = analysis_result["summary"]
    persona = analysis_result["persona"]
    mbti_result = analysis_result["mbti"]
    mct_data = analysis_result["raw_data"]



    with tab_clu:
        st.header("â¤ï¸ 1. ìƒê¶Œ ê·¸ë£¹ ë¶„ì„")
        # 1. area_cluster.csvì—ì„œ ì‚¬ìš©í•  ì—…ì¢…ëª… ë§¤í•‘
        INDUSTRY_MAP = {
            "ğŸ— ê³ ê¸°ì§‘ ğŸ—": "ê³ ê¸°ì§‘",
            "ğŸ ì‹ë£Œí’ˆ ğŸ": "ì‹ë£Œí’ˆ",
            "ğŸ¥ ë² ì´ì»¤ë¦¬ ğŸ¥": "ë² ì´ì»¤ë¦¬",
            "ğŸº ìˆ ì§‘ ğŸº": "ìˆ ì§‘",
            "ğŸ ì–‘ì‹ìŒì‹ì  ğŸ": "ì–‘ì‹ìŒì‹ì ",
            "ğŸ£ ì¼ì‹ìŒì‹ì  ğŸ£": "ì¼ì‹ìŒì‹ì ",
            "ğŸ‘² ì¤‘ì‹ìŒì‹ì  ğŸ‘²": "ì¤‘ì‹ìŒì‹ì ",
            "ğŸ” íŒ¨ìŠ¤íŠ¸í‘¸ë“œì  ğŸ”": "íŒ¨ìŠ¤íŠ¸í‘¸ë“œì ",
            "ğŸš í•œì‹ìŒì‹ì  ğŸš": "í•œì‹ìŒì‹ì "
        }
        
        # 2. í´ëŸ¬ìŠ¤í„° ë°ì´í„° ë¡œë“œ
        df_area_cluster = load_area_cluster_data()
        if df_area_cluster is None:
            st.error("'area_cluster.csv' ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ì—…ì¥ ë³´ê³ ì„œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # 3. ê°€ë§¹ì  ê¸°ë³¸ ì •ë³´(í–‰ì •ë™, ì—…ì¢…ëª…) ì¶”ì¶œ
        try:
            mct_row = df_profile.loc[df_profile["ENCODED_MCT"] == selected_mct].iloc[0]
            h_name = mct_row.get("h_name", "ì •ë³´ì—†ìŒ")
            h_dong = h_name.split(' ')[-1] # í–‰ì •ë™
            industry_name = mct_row.get("HPSN_MCT_ZCD_NM", "ì •ë³´ì—†ìŒ") # ì—…ì¢…

        except IndexError:
            st.error("ì„ íƒí•œ ê°€ë§¹ì ì˜ ê¸°ë³¸ ì •ë³´(h_name, ì—…ì¢…)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        except Exception as e:
            st.error(f"ê°€ë§¹ì  ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            st.stop()
            
        # 4. ì‚¬ìš©ìì—ê²Œ ë¹„êµ ì—…ì¢… ì„ íƒë°›ê¸°
        st.subheader(f"ì ì£¼ë‹˜ì˜ ì—…ì¥ ({industry_name})ì´ ìœ„ì¹˜í•œ [{h_dong}]ì˜ ìƒê¶Œ íŠ¹ì„±ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # 4-1. ì„ íƒ ì˜µì…˜ ë¦¬ìŠ¤íŠ¸ì— ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
        industry_options = ["-- ì ì£¼ë‹˜ì˜ ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš” --"] + list(INDUSTRY_MAP.keys())

        selected_industry_emoji = st.selectbox(
            "ğŸ‘‡ ì—…ì¢…ì„ ì„ íƒí•˜ë©´, ì•„ë˜ì— ìƒê¶Œ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤ ",
            industry_options,
            index=0, # ê¸°ë³¸ê°’ìœ¼ë¡œ 0ë²ˆì§¸(-- ì„ íƒí•˜ì„¸ìš” --)ë¥¼ ì§€ì •
            key="area_cluster_industry_select"
        )

        st.markdown("---")
        
        # --- â¬‡ï¸ ì—…ì¢…ì´ ì„ íƒë˜ì—ˆì„ ë•Œë§Œ í•˜ë‹¨ ë‚´ìš© í‘œì‹œ ---
        if selected_industry_emoji != "-- ì ì£¼ë‹˜ì˜ ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš” --":
            
            # 4-2. ì„ íƒëœ ê²½ìš°ì—ë§Œ ë§¤í•‘ ìˆ˜í–‰
            selected_industry_mapped = INDUSTRY_MAP[selected_industry_emoji]

            # 5. í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ ë° ìœ ì‚¬ í–‰ì •ë™ ì°¾ê¸° (ë“¤ì—¬ì“°ê¸°)
            cluster_text = "í´ëŸ¬ìŠ¤í„° ì •ë³´ ì—†ìŒ"
            similar_dong_sentence = "" 
            cluster_num = None 
            cluster_description = "" # DOCXìš© ë³€ìˆ˜ ì´ˆê¸°í™”
            all_desc = ""            # DOCXìš© ë³€ìˆ˜ ì´ˆê¸°í™”
            
            try:
                cluster_row = df_area_cluster[
                    (df_area_cluster['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'] == selected_industry_mapped) &
                    (df_area_cluster['í–‰ì •ë™_ì½”ë“œ_ëª…'] == h_dong)
                ]

                if not cluster_row.empty:
                    cluster_num = cluster_row['area_cluster'].iloc[0] 
                    cluster_text = f"Cluster {cluster_num}"

                    # ... (ìœ ì‚¬ í–‰ì •ë™ ì°¾ê¸° ë¡œì§) ...
                    similar_dongs_df = df_area_cluster[
                        (df_area_cluster['area_cluster'] == cluster_num) &
                        (df_area_cluster['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'] == selected_industry_mapped)
                    ]
                    similar_dongs_list = similar_dongs_df['í–‰ì •ë™_ì½”ë“œ_ëª…'].unique().tolist()
                    similar_dongs_list = [dong for dong in similar_dongs_list if dong != h_dong]
                    
                    if similar_dongs_list:
                        similar_dongs_str = ", ".join(similar_dongs_list)
                        similar_dong_sentence = f"[{h_dong}]ê³¼ ìœ ì‚¬í•œ ì¶”ì´ë¥¼ ë³´ì´ëŠ” í–‰ì •ë™ìœ¼ë¡œëŠ” [{similar_dongs_str}]ì´ ìˆìŠµë‹ˆë‹¤."
                    else:
                        similar_dong_sentence = f"[{h_dong}]ê³¼ ìœ ì‚¬í•œ ì¶”ì´ë¥¼ ë³´ì´ëŠ” ë‹¤ë¥¸ í–‰ì •ë™ì´ ì—†ìŠµë‹ˆë‹¤."

                else:
                    st.warning(f"ì°¸ê³ : '{h_dong}'ì˜ '{selected_industry_mapped}' ì—…ì¢…ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ 'area_cluster.csv'ì— ì—†ìŠµë‹ˆë‹¤.")

            except KeyError as e:
                st.error(f"'area_cluster.csv' íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼({e})ì´ ì—†ìŠµë‹ˆë‹¤. (ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…, í–‰ì •ë™_ì½”ë“œ_ëª…, area_cluster)")
                cluster_text = "ì˜¤ë¥˜"
            except Exception as e:
                st.error(f"í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                cluster_text = "ì˜¤ë¥˜"

            # 6. ìµœì¢… ê²°ê³¼ ë¬¸êµ¬ í‘œì‹œ
            st.markdown("---")
            st.markdown(f"ì ì£¼ë‹˜ì˜ ì—…ì¥ì€ [{h_dong}]ì— ìœ„ì¹˜í•œ [{industry_name}] ì´ë©°, **[{selected_industry_mapped}-{cluster_text}]**ì— í•´ë‹¹í•©ë‹ˆë‹¤.")
            
            # 7. ìœ ì‚¬ í–‰ì •ë™ ë¬¸ì¥ ì¶œë ¥
            if similar_dong_sentence: 
                st.markdown(similar_dong_sentence)
            
            # 8-1. ì—…ì¢… ì „ì²´ í´ëŸ¬ìŠ¤í„° ìš”ì•½ (cluster.txt) ë° ì´ë¯¸ì§€ í‘œì‹œ
            st.markdown(f"### ì ì£¼ë‹˜ì˜ ì—…ì¥ì´ ì†í•œ **[{selected_industry_mapped} - {cluster_text}]**ì˜ íŠ¹ì§•ì„ ì•Œì•„ë³¼ê¹Œìš”?ğŸ˜Š")
            

            cluster_summary_path = f"./text/{selected_industry_mapped}/cluster.txt"
            if os.path.exists(cluster_summary_path):
                try:
                    with open(cluster_summary_path, 'r', encoding='utf-8') as f:
                        cluster_summary_desc = f.read()
                except UnicodeDecodeError:
                    with open(cluster_summary_path, 'r', encoding='cp949') as f:
                        cluster_summary_desc = f.read()
                except Exception as e:
                    cluster_summary_desc = f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}"
                
                # st.subheader(f"'{selected_industry_mapped}' ì—…ì¢… í´ëŸ¬ìŠ¤í„° ìš”ì•½") # ì œëª©ì´ í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ
                st.markdown(cluster_summary_desc) # ìš”ì•½ í…ìŠ¤íŠ¸ í‘œì‹œ
            else:
                 st.caption(f"[í´ëŸ¬ìŠ¤í„° ìš”ì•½ ì—†ìŒ: {cluster_summary_path}]")
                
                
            image_path = f"./image/{selected_industry_mapped}.png"
            if os.path.exists(image_path):
                st.image(image_path, caption=f"'{selected_industry_mapped}' ì—…ì¢… í´ëŸ¬ìŠ¤í„° ë¶„í¬")
            else:
                st.caption(f"[ì´ë¯¸ì§€ ì—†ìŒ: {image_path}]") 

            # 8-2. íŠ¹ì • í´ëŸ¬ìŠ¤í„° ë¶„ì„ í…ìŠ¤íŠ¸ í‘œì‹œ
            if cluster_num is not None: 
                text_path = f"./text/{selected_industry_mapped}/cluster{cluster_num}.txt"
                if os.path.exists(text_path):
                    try:
                        with open(text_path, 'r', encoding='utf-8') as f:
                            cluster_description = f.read() # ë³€ìˆ˜ì— ì €ì¥
                    except UnicodeDecodeError:
                        with open(text_path, 'r', encoding='cp949') as f:
                            cluster_description = f.read() # ë³€ìˆ˜ì— ì €ì¥
                    except Exception as e:
                        cluster_description = f"í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}"
                    
                    st.subheader(f"â¡ï¸ {cluster_text} ìƒì„¸ ë¶„ì„")
                    st.markdown(cluster_description)
                else:
                    st.caption(f"[ë¶„ì„ ë‚´ìš© ì—†ìŒ: {text_path}]")
                
                # ... (ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„° í† ê¸€ ë¡œì§) ...
                with st.expander(f"ë‹¤ë¥¸ '{selected_industry_mapped}' í´ëŸ¬ìŠ¤í„° ìœ í˜• ì‚´í´ë³´ê¸°"):
                    all_cluster_nums = sorted(df_area_cluster[
                        df_area_cluster['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'] == selected_industry_mapped
                    ]['area_cluster'].unique())
                    
                    found_other = False
                    for c_num in all_cluster_nums:
                        if c_num == cluster_num: continue
                        found_other = True
                        other_text_path = f"./text/{selected_industry_mapped}/cluster{c_num}.txt"
                        if os.path.exists(other_text_path):
                            try:
                                with open(other_text_path, 'r', encoding='utf-8') as f: other_desc = f.read()
                            except UnicodeDecodeError:
                                with open(other_text_path, 'r', encoding='cp949') as f: other_desc = f.read()
                            except Exception as e: other_desc = f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}"
                            st.markdown("---"); st.subheader(f"Cluster {c_num} ë¶„ì„"); st.markdown(other_desc)
                        else:
                            st.caption(f"[ë¶„ì„ ë‚´ìš© ì—†ìŒ: {other_text_path}]")
                    if not found_other: st.caption("ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else: 
                st.caption(f"[í´ëŸ¬ìŠ¤í„° ì •ë³´ ì—†ìŒ: '{h_dong}'ì˜ '{selected_industry_mapped}' ë°ì´í„° í™•ì¸ í•„ìš”]")

            # 8-3. ì—…ì¢…ë³„ all.txt íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
            st.markdown("---")
            all_text_path = f"./text/{selected_industry_mapped}/all.txt"
            if os.path.exists(all_text_path):
                st.subheader(f"'{selected_industry_mapped}' ì—…ì¢… ì „ì²´ ìš”ì•½")
                try:
                    with open(all_text_path, 'r', encoding='utf-8') as f:
                        all_desc = f.read() # ë³€ìˆ˜ì— ì €ì¥
                except UnicodeDecodeError:
                    with open(all_text_path, 'r', encoding='cp949') as f:
                        all_desc = f.read() # ë³€ìˆ˜ì— ì €ì¥
                except Exception as e:
                    all_desc = f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}"
                
                st.markdown(all_desc)
            else:
                st.caption(f"[ì „ì²´ ìš”ì•½ ì—†ìŒ: {all_text_path}]")

            # 9. DOCX ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            
            # DOCX ë°ì´í„° ìƒì„±
            docx_data_clu = create_cluster_report_docx(
                mct_id=selected_mct,
                h_dong=h_dong,
                industry_name=industry_name,
                selected_industry_mapped=selected_industry_mapped,
                cluster_text=cluster_text,
                similar_dong_sentence=similar_dong_sentence,
                cluster_description=cluster_description,
                all_desc=all_desc
            )
            
            st.download_button(
                label="ğŸ“„ ìƒê¶Œ(ì—…ì¥) ë¶„ì„ ë‚´ìš© ì €ì¥í•˜ê¸° (.docx)",
                data=docx_data_clu,
                file_name=f"report_area_{selected_mct}_{selected_industry_mapped}.docx", 
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key="docx_download_clu"
            )
            st.markdown("---") # êµ¬ë¶„ì„ 
        
        else:
            # 4-3. ì—…ì¢…ì´ ì„ íƒë˜ì§€ ì•Šì•˜ì„ ë•Œ
            st.markdown("")

        st.header("â¤ï¸ 2. ìš°ë¦¬ ê°€ê²ŒëŠ” ì–´ë–¤ ìœ í˜•ì¼ê¹Œìš”?")
        # ì„ íƒëœ ê°€ë§¹ì  ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ IDë¡œ ëŒ€ì²´)
        mct_row = df_profile.loc[df_profile["ENCODED_MCT"] == selected_mct]
        merchant_name = (
            mct_row["MCT_NM"].iloc[0]
            if ("MCT_NM" in mct_row.columns and not mct_row.empty and pd.notna(mct_row["MCT_NM"].iloc[0]))
            else str(selected_mct)
        )

        # í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
        cluster_id = get_dtw_cluster(selected_mct)
        if cluster_id is None:
            st.info("ì´ ê°€ë§¹ì ì€ ì•„ì§ DTW êµ°ì§‘ì´ ë§¤í•‘ë˜ì–´ ìˆì§€ ì•ŠìŒ..")
            st.stop()

        # ë¦¬í¬íŠ¸ ìƒì„± (clustering.pyì—ì„œ ë¬¸êµ¬/ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„±)
        report = build_dtw_report(selected_mct, merchant_name)

        # í—¤ë”/ì¸íŠ¸ë¡œ
        st.subheader(report["intro_title"])
        st.markdown(
    f"<p style='font-size:1.1rem; line-height:1.6; font-weight:500;'>{report['intro_body']}</p>",
    unsafe_allow_html=True
)

        # í´ëŸ¬ìŠ¤í„° ë±ƒì§€ ëŠë‚Œ
        badge = report["cluster_badge"]
        st.markdown(f"{badge['icon']} **{badge['name']}**", unsafe_allow_html=True)

        # íŒ¨í„´/í•´ì„/ì£¼ìš” ì—…ì¢…
        with st.container(border=True):
            st.write(report["pattern"])
            st.write(report["key_industries"])
            st.write(report["interpretation"])
            

        # ê·¸ë˜í”„ ì´ë¯¸ì§€
        imgs = report.get("images", [])
        if imgs:
            st.markdown("**ê°™ì€ ê·¸ë£¹ì˜ ìƒìœ„ 10ê°œ ì—…ì¢…ì´ì—ìš”**")
            for p in imgs:
                st.image(p, caption=os.path.basename(p), use_container_width=True)
        else:
            st.caption("ì´ë¯¸ì§€ê°€ ì—†ì–´ìš”. (data/plots ê²½ë¡œ/íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”)")

        # ë©”íƒ€
        st.caption(f"ëª¨ë¸: {report['meta']['model_ver']} Â· ì†ŒìŠ¤: {report['meta']['data_source']}")


    with tab_area:
        @st.cache_data(ttl=3600, show_spinner=False)
        def _auto_load_df_filtered():
            import os
            base_dir = os.path.dirname(FIXED_DATA_PATH)
            csv_path = os.path.join(base_dir, "mapping.csv")
            if not os.path.exists(csv_path):
                raise FileNotFoundError(f"mapping.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
            try:
                df = pd.read_csv(csv_path, encoding="utf-8-sig")
            except UnicodeDecodeError:
                df = pd.read_csv(csv_path, encoding="utf-8")
            return df, base_dir

        try:
            df_filtered, base_dir = _auto_load_df_filtered()
            st.caption(f"ğŸ”„ ìë™ ë¡œë“œ: mapping.csv â€” {len(df_filtered):,}í–‰")
        except Exception as e:
            st.error(f"ìë™ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            st.stop()

        # ì„ íƒ ê°€ë§¹ì (ENCODED_MCT)ê³¼ base_dirì„ ë„˜ê²¨ ìë™ ì—…ì¢… ë§¤í•‘ ì ìš©
        render_area_dashboard(df_filtered, selected_mct=selected_mct, base_dir=base_dir)


    with tab_viz:

        # KPI ë¹„êµ ì°¨íŠ¸
        df = load_data()
        st.subheader("ğŸ“Š ì €ë²ˆ ë‹¬ê³¼ ì´ë§Œí¼ ë‹¬ë¼ìš”")
        kpi_board(df, selected_mct, REF=selected_ref)
        st.markdown("---")
        st.subheader("ğŸ‘¥ ìš°ë¦¬ ê°€ê²Œë¥¼ ì°¾ì€ ì†ë‹˜ë“¤")
        st.write("") 

        col1, col2, col3 = st.columns([1, 1, 1], gap="medium")
        with col1:
            gender_age_pie(df, selected_mct, REF=selected_ref)  # ì„±ë³„Â·ì—°ë ¹ ë„ë„›

        with col2:
            customer_type_pie_revisit_new(df, selected_mct, REF=selected_ref)  # ì¬ë°©ë¬¸ vs ì‹ ê·œ

        with col3:
            customer_type_pie_origin(df, selected_mct, REF=selected_ref) # ê±°ì£¼/ì§ì¥/ìœ ë™

    with tab_llm:

        # 1. ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì§„ë‹¨
        st.subheader("ğŸ¤– AIê°€ í™•ì¸í•œ ìš°ë¦¬ ê°€ê²Œì˜ í˜„ì¬ ìƒíƒœëŠ”?")
        st.success(f"**[ê³ ê°ì¸µ ë¶„ì„]** {summary['cust_analysis_text']}")
        st.info(f"**[ê³ ê° ìœ ì§€ë ¥]** {summary['retention_analysis_text']}")
        st.warning(f"**[ê²½ìŸ í™˜ê²½]** {summary['comp_analysis_text']}")
        st.markdown("---")
        
        # 2. í˜ë¥´ì†Œë‚˜ ë¶„ì„ ê²°ê³¼
        st.subheader("ğŸ¯ ìš°ë¦¬ ê°€ê²Œì˜ í•µì‹¬ ê³ ê°ì€ ëˆ„êµ¬ì¼ê¹Œìš”?")
        
        with st.container(border=True):
            persona_icon = persona.get("icon", "")
            st.markdown(f"#### {persona_icon} {persona['name']}")

            description_html = persona['description'].replace('\n', '<br>')
            goals_html = "<ul>" + "".join([f"<li>{g}</li>" for g in persona['goals']]) + "</ul>"
            pain_points_html = "<ul>" + "".join([f"<li>{p}</li>" for p in persona['pain_points']]) + "</ul>"

            st.markdown(f"""
            <style>
                .persona-table {{
                    width: 100%;
                    border-collapse: collapse;
                    border: none;
                }}
                .persona-table th, .persona-table td {{
                    border: 1px solid #dfe3e8;
                    padding: 12px 15px;
                    text-align: left;
                    vertical-align: top;
                }}
                .persona-table th {{
                    background-color: #f0f2f6;
                    width: 20%;
                    font-weight: bold;
                }}
                .persona-table ul {{
                    padding-left: 20px;
                    margin: 0;
                }}
            </style>
            <table class="persona-table">
                <tr>
                    <th>ì†Œê°œ</th>
                    <td>{description_html}</td>
                </tr>
                <tr>
                    <th>ì°¾ëŠ” ì´ìœ  <br>(Goals)</th>
                    <td>{goals_html}</td>
                </tr>
                <tr>
                    <th>ê²ªëŠ” ì–´ë ¤ì›€ <br>(Pain Points)</th>
                    <td>{pain_points_html}</td>
                </tr>
            </table>
            """, unsafe_allow_html=True)
        
        st.markdown("---")

        st.subheader("ğŸ§  AI ë¹„ë°€ìƒë‹´ì‚¬ì˜ ë§ì¶¤í˜• ë§ˆì¼€íŒ… í”Œëœ")
        st.markdown("ì•„ë˜ëŠ” ì…ë ¥ëœ ë°ì´í„°ì™€ í˜ë¥´ì†Œë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Gemini AI ë§ˆì¼€íŒ… ì „ëµì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        
        with st.expander("ğŸ¯ (ì„ íƒ) íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì§ì ‘ ì„¤ì •í•˜ê¸°", expanded=False):
            st.info("íŠ¹ì • ê³ ê°ì¸µì„ ëŒ€ìƒìœ¼ë¡œ ì „ëµì„ ìƒì„±í•˜ê³  ì‹¶ë‹¤ë©´, ì•„ë˜ì—ì„œ ì§ì ‘ í˜ë¥´ì†Œë‚˜(íƒ€ê²Ÿ)ì„ ì„¤ì •í•˜ì„¸ìš”.")
            
            c1, c2, c3 = st.columns(3)
            with c1:
                target_gender = st.selectbox(
                    "ì„±ë³„", 
                    ["ë°ì´í„° ê¸°ë°˜", "ë‚¨ì„±", "ì—¬ì„±","ë‚¨ì„± ë° ì—¬ì„±"], 
                    key="target_gender_select"
                )
            with c2:
                # ì‚¬ìš©ìê°€ ìš”ì²­í•œ '10ëŒ€'ë¥¼ '10-20ëŒ€'ë¡œ í†µí•©
                target_age = st.selectbox(
                    "ë‚˜ì´", 
                    ["ë°ì´í„° ê¸°ë°˜", "10-20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"], 
                    key="target_age_select"
                )
            with c3:
                # ì‚¬ìš©ìê°€ ìš”ì²­í•œ 'ê°€ì¡±'ì„ ë°ì´í„°ì˜ 'ê±°ì£¼'ì™€ ë§¤í•‘
                target_cust_type = st.selectbox(
                    "ê³ ê° ìœ í˜•", 
                    ["ë°ì´í„° ê¸°ë°˜", "ì§ì¥ì¸", "ìœ ë™ì¸êµ¬", "ê°€ì¡±/ê±°ì£¼"], 
                    key="target_type_select"
                )
                
        _, btn_col, _ = st.columns([1, 2, 1])
        with btn_col:
            button_text = "ğŸš€ ìƒì„±ì¤‘..." if st.session_state.generating else "ğŸš€ AI ë§ˆì¼€íŒ… ì „ëµ ìƒì„±í•˜ê¸°"
            if st.button(button_text, use_container_width=True, type="primary", disabled=st.session_state.generating):
                st.session_state.generating = True
                
                override_target = {}
                if target_gender != "ë°ì´í„° ê¸°ë°˜":
                    override_target['gender'] = target_gender
                if target_age != "ë°ì´í„° ê¸°ë°˜":
                    override_target['age'] = target_age
                if target_cust_type != "ë°ì´í„° ê¸°ë°˜":
                    if target_cust_type == "ê±°ì£¼":
                        override_target['type'] = "ê±°ì£¼"
                    else:
                        override_target['type'] = target_cust_type 
                        
                proposal = generate_marketing_text_with_gemini(
                    summary, 
                    persona, 
                    mbti_result, 
                    selected_mct, 
                    override_target=override_target if override_target else None
                )
                st.session_state['marketing_proposal'] = proposal
                st.session_state.chat_messages = []
                st.session_state.generating = False
                st.rerun()

        st.markdown("---")

        
        if st.session_state.get('marketing_proposal'):
            st.markdown(st.session_state['marketing_proposal'])
            
            st.markdown("---")
            st.subheader("ğŸ¤– AI ë§ˆì¼€íŒ… ë„êµ¬ ì¶”ì²œ")
            st.info("ì•„ë˜ ë„êµ¬ë“¤ê³¼ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œë¥¼ í™œìš©í•˜ì—¬ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ ì†ì‰½ê²Œ ì œì‘í•´ë³´ì„¸ìš”.")

            reel_tab, blog_tab, image_tab = st.tabs(["ğŸ¬ **ë¦´ìŠ¤/ìˆí¼ ì œì‘**", "âœï¸ **ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…**", "ğŸ¨ **ì´ë¯¸ì§€ ìƒì„±**"])

            with reel_tab:
                st.markdown("""
                ### ğŸ”¹ Vrew  
                í…ìŠ¤íŠ¸ë§Œ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ì´ë¯¸ì§€, ì˜ìƒ í´ë¦½, ë”ë¹™ê¹Œì§€ ìƒì„±í•´ì£¼ëŠ” ì˜ìƒ ì œì‘ ë„êµ¬ì…ë‹ˆë‹¤. ë¦´ìŠ¤ë‚˜ ì‡¼ì¸  ì½˜í…ì¸ ë¥¼ ì œì‘í•´ ë³´ì„¸ìš”!
                `https://vrew.voyagerx.com/`
                """)
                with st.expander("ğŸ“ **Vrew í™œìš© í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ í¼ì³ë³´ê¸°**"):
                    st.code(f"""
                    ### ë¦´ìŠ¤ ëŒ€ë³¸ ìƒì„± í”„ë¡¬í”„íŠ¸

                    **ì—­í• :**
                    ë‹¹ì‹ ì€ '{summary['static_info'].get('HPSN_MCT_ZCD_NM')}' ê°€ê²Œë¥¼ ìš´ì˜í•˜ëŠ” ì‚¬ì¥ë‹˜ ì—­í• ì„ ë§¡ì€ SNS ë§ˆì¼€í„°ì…ë‹ˆë‹¤.
                    ìš°ë¦¬ì˜ í•µì‹¬ ê³ ê°ì¸ '{persona['name']}'ì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” 30ì´ˆ ë¶„ëŸ‰ì˜ ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

                    **ë¦´ìŠ¤ ì»¨ì…‰:**
                    [ì‚¬ì¥ë‹˜ì´ ì§ì ‘ ê°€ê²Œì˜ ë§¤ë ¥ì„ ì†Œê°œí•˜ëŠ” ì»¨ì…‰ / ê³ ê°ì´ ì§ì ‘ ê²½í—˜í•˜ëŠ” ë“¯í•œ 1ì¸ì¹­ ì‹œì  ì»¨ì…‰ ë“±]

                    **í•µì‹¬ ë©”ì‹œì§€:**
                    '{persona['goals'][0]}' ì™€ ê°™ì€ ê³ ê°ì˜ ë‹ˆì¦ˆë¥¼ ì¶©ì¡±ì‹œí‚¤ê³ , '{persona['pain_points'][0]}' ê°™ì€ ë¶ˆí¸í•¨ì„ í•´ê²°í•´ì¤€ë‹¤ëŠ” ì ì„ ê°•ì¡°í•´ì£¼ì„¸ìš”.

                    **í¬í•¨í•  ë‚´ìš©:**
                    - ì‹œì„ ì„ ì‚¬ë¡œì¡ëŠ” ì˜¤í”„ë‹ ë©˜íŠ¸ (3ì´ˆ ì´ë‚´)
                    - ê°€ê²Œì˜ í•µì‹¬ ë©”ë‰´ ë˜ëŠ” ì„œë¹„ìŠ¤ ì†Œê°œ
                    - ê³ ê°ì—ê²Œ ì œê³µí•˜ëŠ” íŠ¹ë³„í•œ í˜œíƒ (ì´ë²¤íŠ¸, í• ì¸ ë“±)
                    - í–‰ë™ ìœ ë„ ë¬¸êµ¬ (ì˜ˆ: "ì§€ê¸ˆ ë°”ë¡œ í”„ë¡œí•„ ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
                    - ì˜ìƒ ì¥ë©´ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… (ì˜ˆ: #1. ìŒì‹ì´ í´ë¡œì¦ˆì—…ë˜ëŠ” ì¥ë©´)

                    **ë¶„ìœ„ê¸°:**
                    [í™œê¸°ì°¬ / ê°ì„±ì ì¸ / ìœ ë¨¸ëŸ¬ìŠ¤í•œ] ë¶„ìœ„ê¸°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    """, language="markdown")

            # âœï¸ ë¸”ë¡œê·¸ íƒ­
            with blog_tab:
                st.markdown("""
                ### ğŸ”¹ Gemini  
                ê°•ë ¥í•œ AI ë¹„ì„œë¡œ ì™„ì„±ë„ ë†’ì€ ë¸”ë¡œê·¸ ê¸€ì„ ì†ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆì–´ìš”!
                `https://gemini.google.com/`
                
                ### ğŸ”¹ ë¤¼íŠ¼(Wrtn) ë¸”ë¡œê·¸  
                ê²Œì‹œë¬¼ì˜ ì£¼ì œ, ë§íˆ¬ë¥¼ ì„¤ì •í•˜ë©´ ë¸”ë¡œê·¸ ê¸€ì„ ìë™ìœ¼ë¡œ ì™„ì„±í•´ ë“œë ¤ìš”!  
                `https://wrtn.ai/tools/67b2e7901b44a4d864b127a5`
                """)
                with st.expander("ğŸ“ **ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…ìš© í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ í¼ì³ë³´ê¸°**"):
                    st.code(f"""
                    ### ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸

                    **ì—­í• :**
                    ë‹¹ì‹ ì€ '{summary['static_info'].get('h_name', row.get('HPSN_MCT_BZN_CD_NM'))}' ìƒê¶Œì˜ ë§›ì§‘ì„ ì†Œê°œí•˜ëŠ” ì „ë¬¸ ë¸”ë¡œê±°ì…ë‹ˆë‹¤.

                    **ì£¼ì œ:**
                    '{summary['static_info'].get('HPSN_MCT_ZCD_NM')}' ê°€ê²Œ ë°©ë¬¸ í›„ê¸°

                    **íƒ€ê²Ÿ ë…ì:**
                    '{persona['name']}' ({persona['description']})

                    **ê¸€ì˜ ëª©ì :**
                    íƒ€ê²Ÿ ë…ìê°€ ì´ ê¸€ì„ ì½ê³  ìš°ë¦¬ ê°€ê²Œì— ë°©ë¬¸í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ê²ƒ.
                    íŠ¹íˆ, '{persona['goals'][0]}'ì™€ ê°™ì€ ë…ìì˜ ëª©í‘œë¥¼ ìš°ë¦¬ ê°€ê²Œê°€ ì–´ë–»ê²Œ ë§Œì¡±ì‹œì¼œì£¼ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ ì£¼ì„¸ìš”.

                    **í¬í•¨í•  ë‚´ìš©:**
                    1.  ë…ìì˜ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ëŠ” ì œëª© (SEO í‚¤ì›Œë“œ: [ì§€ì—­ëª…] ë§›ì§‘, [ì—…ì¢…ëª…])
                    2.  ê°€ê²Œì˜ ì²«ì¸ìƒ ë° ë¶„ìœ„ê¸° ë¬˜ì‚¬
                    3.  ì£¼ë¬¸í•œ ë©”ë‰´ì™€ ë§›ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…
                    4.  '{persona['pain_points'][0]}'ê³¼ ê°™ì€ ë…ìì˜ ë¶ˆí¸í•¨ì„ ìš°ë¦¬ ê°€ê²Œê°€ ì–´ë–»ê²Œ í•´ê²°í•´ì£¼ëŠ”ì§€ì— ëŒ€í•œ í¬ì¸íŠ¸ ê°•ì¡°
                    5.  ê°€ê²Œ ìœ„ì¹˜, ìš´ì˜ ì‹œê°„, íŒ ë“± ë°©ë¬¸ ì •ë³´
                    6.  ë…ìì˜ ë°©ë¬¸ì„ ìœ ë„í•˜ëŠ” ë§ˆë¬´ë¦¬ ë¬¸ë‹¨

                    **ê¸€ì˜ í†¤ì•¤ë§¤ë„ˆ:**
                    [ì¹œê·¼í•˜ê³  ì†”ì§í•œ / ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ”] í†¤ì•¤ë§¤ë„ˆë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    """, language="markdown")

            # ğŸ¨ ì´ë¯¸ì§€ ìƒì„± íƒ­
            with image_tab:
                st.markdown("""
                ### ğŸ”¹ ë¤¼íŠ¼(Wrtn) ì´ë¯¸ì§€  
                í•œêµ­ì–´ì— ê°•í•œ AIë¡œ, ì†ì‰½ê²Œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆì–´ìš”! 
                `https://wrtn.ai/tools/67b2e7901b44a4d864b127b9`

                ### ğŸ”¹ Hailo AI  
                AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ì™€ ì˜ìƒì„ ìƒì„±í•˜ê³  í¸ì§‘í•  ìˆ˜ ìˆì–´ìš”!
                `https://hailuoai.video/ko/agent`

                ### ğŸ”¹ í”Œë ˆì´ê·¸ë¼ìš´ë“œ(ë¡œê³ ) 
                ê°„ë‹¨í•œ ì…ë ¥ë§Œìœ¼ë¡œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ë‚´ ê°€ê²Œì˜ ë¡œê³ ë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”!  
                `https://playground.com/design/c/logo`
                """)

                with st.expander("ğŸ“ **ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ í¼ì³ë³´ê¸°**"):
                    st.code(f"""
                    ### ë§ˆì¼€íŒ… ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸

                    **ìŠ¤íƒ€ì¼:**
                    [ì‹¤ì‚¬ ì‚¬ì§„ / ë””ì§€í„¸ ì•„íŠ¸ / ìˆ˜ì±„í™” / ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼]

                    **ìƒì„¸ ì„¤ëª…:**
                    SNS ê´‘ê³ ì— ì‚¬ìš©í•  ìƒë™ê° ìˆê³  ë§¤ë ¥ì ì¸ ì´ë¯¸ì§€.
                    '{summary['static_info'].get('HPSN_MCT_ZCD_NM')}' ì‹ë‹¹ì—ì„œ '{persona['name']}' ê³ ê°ì´ ë§Œì¡±ìŠ¤ëŸ½ê²Œ ì‹ì‚¬ë¥¼ ì¦ê¸°ê³  ìˆëŠ” ì¥ë©´.
                    '{persona['goals'][0]}'ì™€ ê°™ì€ ê¸°ë¶„ì„ ëŠë¼ë©° ë§¤ìš° ë§Œì¡±ìŠ¤ëŸ¬ì›Œ ë³´ì´ëŠ” í‘œì •.
                    ë¶„ìœ„ê¸°ëŠ” [ì•„ëŠ‘í•˜ê³  ë”°ëœ»í•œ / ë°ê³  í˜„ëŒ€ì ì¸ / í™œê¸°ì°¨ê³  íŠ¸ë Œë””í•œ] ëŠë‚Œ.
                    ë©”ì¸ ë©”ë‰´ê°€ í…Œì´ë¸” ìœ„ì— ì•„ë¦„ë‹µê²Œ í”Œë ˆì´íŒ… ë˜ì–´ ìˆìŒ.
                    ë””í…Œì¼ì´ ë›°ì–´ë‚˜ê³  ë”°ëœ»í•˜ë©° ë§¤ë ¥ì ì¸ ì¡°ëª…ì— ì´ˆì ì„ ë§ì¶œ ê²ƒ.

                    **í•µì‹¬ í‚¤ì›Œë“œ:**
                    ë§›ìˆëŠ” ìŒì‹, í–‰ë³µí•œ ê³ ê°, {summary['static_info'].get('h_name', row.get('HPSN_MCT_BZN_CD_NM'))}, ë¼ì´í”„ìŠ¤íƒ€ì¼, ê³ í’ˆì§ˆ
                    """, language="markdown")

            st.markdown("---")
            st.subheader("ğŸ¤– ì¶”ê°€ ìƒë‹´í•˜ê¸°")
            
            if not st.session_state.chat_messages:
                st.session_state.chat_messages.append(
                    {"role": "assistant", "content": "ë°©ê¸ˆ ìƒì„±ëœ ë§ˆì¼€íŒ… ì „ëµì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”."}
                )

            for message in st.session_state.chat_messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            if prompt := st.chat_input("ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
                st.session_state.chat_messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner("AIê°€ ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                        response = generate_chat_response_with_gemini(
                            base_context=f"ë¶„ì„ì •ë³´: {summary}, í˜ë¥´ì†Œë‚˜: {persona}, ì›ë³¸ì „ëµ: {st.session_state.marketing_proposal}",
                            messages_history=st.session_state.chat_messages
                        )
                        st.markdown(response)
                        st.session_state.chat_messages.append({"role": "assistant", "content": response})
            
            st.markdown("---") 
            
            docx_data = create_docx_report(
                selected_mct,
                st.session_state['marketing_proposal'],
                st.session_state.get('chat_messages', [])
            )
            
            st.download_button(
                label="ğŸ“„ ì „ì²´ ë‚´ìš© ë¬¸ì„œë¡œ ì €ì¥í•˜ê¸° (.docx)",
                data=docx_data,
                file_name=f"report_{selected_mct}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.info("ğŸ‘† ë²„íŠ¼ì„ ëˆŒëŸ¬ ìš°ë¦¬ ê°€ê²Œë§Œì„ ìœ„í•œ ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµì„ í™•ì¸í•´ë³´ì„¸ìš”!")
    
if __name__ == '__main__':
    main()
