import pandas as pd
import numpy as np
import os
from collections import Counter
from typing import Dict, Any

# --- ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ ---
from persona_generator import create_persona
from mbti_classifier import classify_merchant_mbti

# ==============================================================================
# --- ìƒìˆ˜ ì •ì˜ ---
# ==============================================================================
FIXED_DATA_PATH = "./data/merged_data.csv"
STATIC_COLS = [
    'MCT_BSE_AR', 'MCT_SIGUNGU_NM', 'HPSN_MCT_ZCD_NM', 'HPSN_MCT_BZN_CD_NM',
    'ARE_D', 'MCT_ME_D'
]
QUARTILE_METRIC_COLS = [
    'MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT',
    'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT'
]
QUARTILE_MAPPING = {
    '10%ì´í•˜': 'ìƒìœ„ 10%', '10-25%': 'ìƒìœ„ 10-25%', '25-50%': 'ì¤‘ìœ„ 25-50%',
    '50-75%': 'í•˜ìœ„ 50-75%', '75-90%': 'í•˜ìœ„ 75-90%', '90%ì´ˆê³¼': 'í•˜ìœ„ 90% ì´ˆê³¼'
}
AGE_GENDER_COLS = [
    'M12_MAL_1020_RAT', 'M12_MAL_30_RAT', 'M12_MAL_40_RAT', 'M12_MAL_50_RAT', 'M12_MAL_60_RAT',
    'M12_FME_1020_RAT', 'M12_FME_30_RAT', 'M12_FME_40_RAT', 'M12_FME_50_RAT', 'M12_FME_60_RAT'
]
AGE_GENDER_NAMES = {
    'M12_MAL_1020_RAT': 'ë‚¨ì„± 20ëŒ€ì´í•˜', 'M12_MAL_30_RAT': 'ë‚¨ì„± 30ëŒ€', 'M12_MAL_40_RAT': 'ë‚¨ì„± 40ëŒ€',
    'M12_MAL_50_RAT': 'ë‚¨ì„± 50ëŒ€', 'M12_MAL_60_RAT': 'ë‚¨ì„± 60ëŒ€ì´ìƒ',
    'M12_FME_1020_RAT': 'ì—¬ì„± 20ëŒ€ì´í•˜', 'M12_FME_30_RAT': 'ì—¬ì„± 30ëŒ€', 'M12_FME_40_RAT': 'ì—¬ì„± 40ëŒ€',
    'M12_FME_50_RAT': 'ì—¬ì„± 50ëŒ€', 'M12_FME_60_RAT': 'ì—¬ì„± 60ëŒ€ì´ìƒ'
}
CUST_TYPE_COLS = [
    'RC_M1_SHC_RSD_UE_CLN_RAT', 'RC_M1_SHC_WP_UE_CLN_RAT', 'RC_M1_SHC_FLP_UE_CLN_RAT'
]
CUST_TYPE_NAMES = {
    'RC_M1_SHC_RSD_UE_CLN_RAT': 'ê±°ì£¼ ì´ìš© ê³ ê°',
    'RC_M1_SHC_WP_UE_CLN_RAT': 'ì§ì¥ ì´ìš© ê³ ê°',
    'RC_M1_SHC_FLP_UE_CLN_RAT': 'ìœ ë™ì¸êµ¬ ì´ìš© ê³ ê°'
}
MEAN_COLS_FOR_AGG = [
    'DLV_SAA_RAT', 'M12_SME_RY_SAA_PCE_RT', 'M12_SME_BZN_SAA_PCE_RT',
] + AGE_GENDER_COLS + CUST_TYPE_COLS + ['MCT_UE_CLN_REU_RAT', 'MCT_UE_CLN_NEW_RAT']
SV_VALUE = -999999.9

def get_mode_or_first(series):
    counts = Counter(series.dropna())
    if not counts: return None
    return counts.most_common(1)[0][0]

def preprocess_data(df: pd.DataFrame):
    df[MEAN_COLS_FOR_AGG] = df[MEAN_COLS_FOR_AGG].apply(pd.to_numeric, errors='coerce')
    df = df.replace(SV_VALUE, np.nan)
    df_static = df.groupby('ENCODED_MCT')[STATIC_COLS].first().reset_index()
    df_avg = df.groupby('ENCODED_MCT')[MEAN_COLS_FOR_AGG].mean().reset_index()
    agg_quartile_funcs = {col: get_mode_or_first for col in QUARTILE_METRIC_COLS}
    df_quartile = df.groupby('ENCODED_MCT').agg(agg_quartile_funcs).reset_index()
    df_final = pd.merge(df_static, df_avg, on='ENCODED_MCT', how='left')
    df_final = pd.merge(df_final, df_quartile, on='ENCODED_MCT', how='left')
    return df_final

def load_fixed_data(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ íŒŒì¼ ì—†ìŒ: `{path}`")
    df_raw = pd.read_csv(path, encoding='cp949')
    return preprocess_data(df_raw)

# ==============================================================================
# --- ğŸŒŸ ê°€ë§¹ì  í†µí•© ë¶„ì„ í•¨ìˆ˜ ---
# ==============================================================================
def analyze_merchant(merchant_row: pd.Series) -> Dict[str, Any]:
    """ì„ íƒëœ ê°€ë§¹ì ì˜ ëª¨ë“  ë¶„ì„(ì§„ë‹¨, í˜ë¥´ì†Œë‚˜, MBTI)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    # --- 1. 3ê°€ì§€ í•µì‹¬ ì§„ë‹¨ ---
    age_gender_ratios = merchant_row[AGE_GENDER_COLS].dropna()
    max_ag_ratio = age_gender_ratios.max() if not age_gender_ratios.empty else 0.0
    dominant_ag_name = AGE_GENDER_NAMES.get(age_gender_ratios.idxmax(), 'ì •ë³´ ì—†ìŒ') if not age_gender_ratios.empty else 'ì •ë³´ ì—†ìŒ'
    primary_ct_ratios = merchant_row[CUST_TYPE_COLS].dropna()
    primary_ct_name = CUST_TYPE_NAMES.get(primary_ct_ratios.idxmax(), 'ì •ë³´ ì—†ìŒ').replace(' ì´ìš© ê³ ê°', '') if not primary_ct_ratios.empty else 'ì •ë³´ ì—†ìŒ'
    cust_analysis_text = f"ìš°ë¦¬ ê°€ê²ŒëŠ” **{dominant_ag_name} {primary_ct_name}** ê³ ê° ë¹„ì¤‘ì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤."

    repeat_rate = merchant_row.get('MCT_UE_CLN_REU_RAT', np.nan)
    retention_analysis_text = (f"**ì¬ë°©ë¬¸ìœ¨({repeat_rate:.1f}%)ì´ ì–‘í˜¸**í•©ë‹ˆë‹¤." if repeat_rate > 30 else f"**ì¬ë°©ë¬¸ìœ¨({repeat_rate:.1f}%)ì´ ë‚®ì•„** ë‹¨ê³¨ í™•ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.") if pd.notna(repeat_rate) else "ì¬ë°©ë¬¸ìœ¨ ì •ë³´ ë¶€ì¡±"

    ry_rank = merchant_row.get('M12_SME_RY_SAA_PCE_RT', np.nan)
    comp_analysis_text = (f"ì—…ì¢… ë‚´ **ìƒìœ„ {(100 - ry_rank):.1f}%**ì˜ ì¤€ìˆ˜í•œ ê²½ìŸë ¥ì…ë‹ˆë‹¤." if ry_rank < 70 else f"ì—…ì¢… ë‚´ **í•˜ìœ„ {(100-ry_rank):.1f}%**ë¡œ ê²½ìŸë ¥ ê°•í™”ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤.") if pd.notna(ry_rank) else "ê²½ìŸ í™˜ê²½ ì •ë³´ ë¶€ì¡±"

    summary_data = {
        'cust_analysis_text': cust_analysis_text,
        'retention_analysis_text': retention_analysis_text,
        'comp_analysis_text': comp_analysis_text,
        'static_info': merchant_row[STATIC_COLS].to_dict(),
        'metric_info': merchant_row[QUARTILE_METRIC_COLS].to_dict(),
        'dominant_ag_group': dominant_ag_name,
        'primary_cust_type': primary_ct_name,
        'dominant_ag_ratio': max_ag_ratio
    }

    # --- 2. í˜ë¥´ì†Œë‚˜ ë° ê°€ê²Œ ìœ í˜• ë¶„ì„ ---
    persona_info = create_persona(merchant_row, summary_data)
    mbti_info = classify_merchant_mbti(merchant_row)

    # [ìˆ˜ì •] image_urlì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ê³ ì •ëœ ëŒ€ì²´ ì´ë¯¸ì§€ URLì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    if 'image_url' not in persona_info:
        persona_info['image_url'] = "https://images.unsplash.com/photo-1573496359142-b8d87734a5a2?q=80&w=1888&auto=format&fit=crop"


    # --- 3. ìµœì¢… ê²°ê³¼ ì¢…í•© ---
    return {
        'summary': summary_data,
        'persona': persona_info,
        'mbti': mbti_info,
        'raw_data': merchant_row
    }